name: Text-to-Image with Ngrok

on:
  workflow_dispatch:
    inputs:
      prompt:
        description: 'Text prompt for image generation'
        required: true
        default: 'A beautiful sunset, digital art'
      port:
        description: 'Local port for web interface'
        required: true
        default: 7860
        type: number

jobs:
  text-to-image:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libgl1 libglib2.0-0 wget

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
        pip install diffusers transformers accelerate
        pip install pillow numpy requests
        pip install gradio

    - name: Install Ngrok
      run: |
        wget -q -O ngrok.tgz https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz
        tar -xzf ngrok.tgz
        chmod +x ngrok
        sudo mv ngrok /usr/local/bin/
        echo "Ngrok version:"
        ngrok version

    - name: Setup Ngrok authentication
      run: |
        ngrok authtoken "${{ secrets.NGROK_AUTH_TOKEN }}"
        echo "âœ… Ngrok authentication configured"

    - name: Create outputs directory
      run: mkdir -p outputs

    - name: Create lightweight text-to-image app
      run: |
        cat > app.py << 'EOF'
import gradio as gr
import torch
from diffusers import StableDiffusionPipeline
from PIL import Image
import datetime
import os
import requests
from io import BytesIO
import time

# Use a smaller model to save memory
MODEL_ID = "OFA-Sys/small-stable-diffusion-v0"  # Much smaller model

def download_image_from_url(url):
    """Download image from URL as fallback"""
    try:
        response = requests.get(url, timeout=10)
        img = Image.open(BytesIO(response.content))
        return img
    except:
        return None

def create_placeholder_image(prompt, width=512, height=512):
    """Create a placeholder image"""
    from PIL import Image, ImageDraw, ImageFont
    
    img = Image.new('RGB', (width, height), color=(40, 40, 80))
    draw = ImageDraw.Draw(img)
    
    # Draw border
    draw.rectangle([10, 10, width-10, height-10], outline=(100, 100, 200), width=3)
    
    # Draw centered text
    lines = [
        "ðŸŽ¨ AI Image Generator",
        "",
        f"Prompt: {prompt}",
        "",
        "Model: Small Stable Diffusion",
        f"Time: {datetime.datetime.now().strftime('%H:%M:%S')}",
        "",
        "â¬‡ï¸ Generating...",
        "This may take 1-2 minutes"
    ]
    
    y_position = height // 2 - (len(lines) * 15)
    for line in lines:
        text_width = len(line) * 9
        x_position = (width - text_width) // 2
        draw.text((x_position, y_position), line, fill=(200, 200, 255))
        y_position += 30
    
    return img

def generate_image(prompt, steps=20, guidance=7.5):
    """Generate image from text prompt"""
    try:
        print(f"Starting generation: {prompt}")
        
        # Show placeholder immediately
        placeholder = create_placeholder_image(prompt)
        
        # Load model (this will take time)
        print("Loading model...")
        pipe = StableDiffusionPipeline.from_pretrained(
            MODEL_ID,
            torch_dtype=torch.float32,
            use_safetensors=True
        )
        pipe = pipe.to("cpu")
        pipe.enable_attention_slicing()
        
        print("Generating image...")
        # Generate with progress indication
        image = pipe(
            prompt=prompt,
            num_inference_steps=steps,
            guidance_scale=guidance,
            generator=torch.Generator(device="cpu").manual_seed(42)
        ).images[0]
        
        # Save the image
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"outputs/image_{timestamp}.png"
        image.save(filename)
        
        # Log generation
        with open("outputs/generation_log.txt", "a") as f:
            f.write(f"{timestamp} | {prompt} | {filename}\n")
        
        success_msg = f"âœ… Generated: {filename}"
        print(success_msg)
        return image, success_msg
        
    except Exception as e:
        error_msg = f"âŒ Error: {str(e)}"
        print(error_msg)
        
        # Create error image
        error_img = create_placeholder_image(f"Error: {str(e)[:50]}...")
        return error_img, error_msg

# Create simple Gradio interface
with gr.Blocks(theme=gr.themes.Soft(), title="AI Image Generator") as demo:
    gr.Markdown("""
    # ðŸŽ¨ Text-to-Image Generator
    *Generate images using AI - Running on GitHub Actions*
    """)
    
    with gr.Row():
        with gr.Column():
            prompt = gr.Textbox(
                label="Describe your image",
                value="${{ github.event.inputs.prompt }}",
                lines=3,
                placeholder="A beautiful sunset over mountains, digital art style..."
            )
            
            with gr.Row():
                steps = gr.Slider(5, 30, value=15, label="Steps", step=1)
                guidance = gr.Slider(1.0, 10.0, value=7.0, label="Guidance", step=0.5)
            
            generate_btn = gr.Button("âœ¨ Generate Image", variant="primary", size="lg")
            status = gr.Textbox(label="Status", interactive=False)
        
        with gr.Column():
            output_image = gr.Image(
                label="Generated Image", 
                height=400,
                show_download_button=True
            )
    
    # Examples
    gr.Examples(
        examples=[
            ["A serene lake surrounded by pine trees, misty morning, digital painting"],
            ["A cyberpunk cityscape at night with neon lights, futuristic"],
            ["A cute cartoon robot playing guitar, colorful, animated style"],
            ["A majestic dragon flying over medieval castle, fantasy art"],
            ["A bowl of fresh fruit on a wooden table, photorealistic"]
        ],
        inputs=prompt
    )
    
    # Generation function
    def generate_wrapper(prompt, steps, guidance):
        if not prompt.strip():
            return None, "âš ï¸ Please enter a prompt"
        return generate_image(prompt, int(steps), float(guidance))
    
    generate_btn.click(
        fn=generate_wrapper,
        inputs=[prompt, steps, guidance],
        outputs=[output_image, status]
    )

if __name__ == "__main__":
    print("ðŸš€ Starting Gradio server...")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        quiet=False,
        show_error=True
    )
EOF

    - name: Start the web app
      run: |
        echo "Starting Gradio web interface..."
        python app.py &
        echo "APP_PID=$!" >> $GITHUB_ENV
        sleep 15
        echo "âœ… Web app started"

    - name: Start Ngrok tunnel
      run: |
        echo "Starting Ngrok tunnel..."
        ngrok http 7860 --log=stdout > ngrok.log 2>&1 &
        echo "NGROK_PID=$!" >> $GITHUB_ENV
        sleep 10
        echo "âœ… Ngrok tunnel starting..."

    - name: Get Ngrok public URL
      id: get_url
      run: |
        echo "Waiting for Ngrok tunnel..."
        sleep 10
        
        max_attempts=8
        for i in $(seq 1 $max_attempts); do
          echo "Attempt $i to get Ngrok URL..."
          
          if curl -s http://localhost:4040/api/tunnels > /dev/null 2>&1; then
            NGROK_URL=$(curl -s http://localhost:4040/api/tunnels | jq -r '.tunnels[0].public_url // empty' 2>/dev/null || echo "")
            
            if [ -n "$NGROK_URL" ] && [ "$NGROK_URL" != "null" ]; then
              echo "âœ… Ngrok URL found: $NGROK_URL"
              echo "ngrok_url=$NGROK_URL" >> $GITHUB_OUTPUT
              echo "NGROK_PUBLIC_URL=$NGROK_URL" >> $GITHUB_ENV
              break
            fi
          fi
          
          if [ $i -eq $max_attempts ]; then
            echo "âŒ Failed to get Ngrok URL after $max_attempts attempts"
            echo "Debug info:"
            ps aux | grep ngrok || true
            echo "Ngrok log:"
            cat ngrok.log | tail -20 || true
            # Continue anyway with a placeholder
            echo "ngrok_url=https://placeholder.ngrok.io" >> $GITHUB_OUTPUT
            echo "NGROK_PUBLIC_URL=https://placeholder.ngrok.io" >> $GITHUB_ENV
          fi
          
          sleep 5
        done

    - name: Display connection info
      run: |
        echo ""
        echo "âœ¨ ========================================="
        echo "âœ¨   TEXT-TO-IMAGE GENERATOR READY!"
        echo "âœ¨ ========================================="
        echo "âœ¨ Web Interface: $NGROK_PUBLIC_URL"
        echo "âœ¨ Local Port: 7860"
        echo "âœ¨ Model: Small Stable Diffusion"
        echo "âœ¨ Status: ðŸŸ¢ Active"
        echo "âœ¨ ========================================="
        echo ""
        echo "ðŸ“ Instructions:"
        echo "   1. Open the URL above in your browser"
        echo "   2. Enter your prompt or use examples"
        echo "   3. Click 'Generate Image'"
        echo "   4. Wait 1-2 minutes for generation"
        echo ""
        echo "ðŸ’¡ Tip: Start with simple prompts for faster results"

    - name: Test web interface
      run: |
        echo "Testing web interface accessibility..."
        if curl -f -s "$NGROK_PUBLIC_URL" > /dev/null 2>&1; then
          echo "âœ… Web interface is accessible"
        else
          echo "âš ï¸  Cannot reach web interface directly"
          echo "The tunnel might still be establishing..."
        fi

    - name: Monitor and keep alive
      run: |
        echo ""
        echo "ðŸ• Service will remain active for 25 minutes..."
        echo "ðŸŒ Your URL: $NGROK_PUBLIC_URL"
        echo ""
        echo "ðŸ“Š Monitoring logs (Ctrl+C to stop early):"
        echo "=========================================="
        
        # Monitor for 25 minutes
        for i in {1..150}; do
          minutes=$((i/6))
          seconds=$((i%6*10))
          
          # Check service status every 2 minutes
          if [ $((i % 12)) -eq 0 ]; then
            if curl -s "$NGROK_PUBLIC_URL" > /dev/null 2>&1; then
              echo "[$(date +%H:%M:%S)] âœ… Service healthy - Active: ${minutes}m ${seconds}s"
            else
              echo "[$(date +%H:%M:%S)] âš ï¸  Service unreachable"
            fi
            
            # Check for new images
            image_count=$(find outputs/ -name "*.png" 2>/dev/null | wc -l)
            echo "   ðŸ“· Total images generated: $image_count"
          else
            echo "[$(date +%H:%M:%S)] Active: ${minutes}m ${seconds}s"
          fi
          
          sleep 10
        done

    - name: Upload generated images
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ai-generated-images
        path: outputs/
        retention-days: 30
        if-no-files-found: warn

    - name: Final cleanup
      if: always()
      run: |
        echo "ðŸ§¹ Cleaning up..."
        # Kill processes
        pkill -f "python app.py" 2>/dev/null || true
        pkill -f ngrok 2>/dev/null || true
        # Wait a bit for cleanup
        sleep 3
        echo "âœ… Cleanup complete"
        
        # Show final image count
        echo "ðŸ“Š Final stats:"
        find outputs/ -name "*.png" 2>/dev/null | wc -l | xargs echo "Total images generated:"
        ls -la outputs/ 2>/dev/null || echo "No outputs directory"
