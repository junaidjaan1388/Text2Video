name: Text-to-Image with Ngrok Tunnel

on:
  workflow_dispatch:
    inputs:
      prompt:
        description: 'Text prompt for image generation'
        required: true
        default: 'A beautiful sunset over mountains, digital art'
      model:
        description: 'Diffusion model to use'
        required: true
        default: 'runwayml/stable-diffusion-v1-5'
        type: choice
        options:
          - 'runwayml/stable-diffusion-v1-5'
          - 'stabilityai/stable-diffusion-2-1'
      steps:
        description: 'Number of inference steps'
        required: true
        default: 20
        type: number
      guidance:
        description: 'Guidance scale'
        required: true
        default: 7.5
        type: number
      port:
        description: 'Local port for web interface'
        required: true
        default: 7860
        type: number

jobs:
  text-to-image:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          libgl1 \
          libglib2.0-0 \
          wget

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
        pip install diffusers transformers accelerate
        pip install pillow numpy requests
        pip install gradio

    - name: Install Ngrok
      run: |
        wget -q -O ngrok.tgz https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz
        tar -xzf ngrok.tgz
        chmod +x ngrok
        sudo mv ngrok /usr/local/bin/
        ngrok version

    - name: Setup Ngrok authentication
      run: |
        ngrok authtoken "${{ secrets.NGROK_AUTH_TOKEN }}"
        echo "âœ… Ngrok authentication configured"

    - name: Create outputs directory
      run: mkdir -p outputs

    - name: Create text-to-image web app
      run: |
        cat > app.py << 'EOF'
import gradio as gr
import torch
from diffusers import StableDiffusionPipeline
from PIL import Image
import datetime
import os

pipe = None
model_loaded = False
current_model = ""

def load_model(model_id):
    global pipe, model_loaded, current_model
    try:
        if model_loaded and current_model == model_id:
            return f"âœ… Model {model_id} already loaded"
            
        print(f"Loading model: {model_id}")
        pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float32,
            use_safetensors=True
        )
        pipe = pipe.to("cpu")
        pipe.enable_attention_slicing()
        model_loaded = True
        current_model = model_id
        print(f"âœ… Model {model_id} loaded successfully")
        return f"âœ… Model {model_id} loaded successfully"
    except Exception as e:
        error_msg = f"âŒ Failed to load model: {str(e)}"
        print(error_msg)
        return error_msg

def create_fallback_image(prompt):
    from PIL import Image, ImageDraw
    import random
    
    width, height = 512, 512
    color = (random.randint(50, 200), random.randint(50, 200), random.randint(50, 200))
    img = Image.new('RGB', (width, height), color=color)
    draw = ImageDraw.Draw(img)
    
    draw.rectangle([10, 10, width-10, height-10], outline='white', width=3)
    draw.ellipse([width//2-60, height//2-60, width//2+60, height//2+60], fill='yellow')
    
    lines = [
        "ðŸŽ¨ AI Image Generator",
        f"Prompt: {prompt}",
        "Model Loading...",
        f"Time: {datetime.datetime.now().strftime('%H:%M:%S')}"
    ]
    
    y_pos = height // 2 - 80
    for line in lines:
        text_width = len(line) * 10
        x_pos = (width - text_width) // 2
        draw.text((x_pos, y_pos), line, fill='black')
        y_pos += 25
    
    return img

def generate_image(prompt, model_id, steps, guidance_scale):
    global pipe, model_loaded
    
    if not model_loaded:
        load_status = load_model(model_id)
        if "âŒ" in load_status:
            return create_fallback_image(prompt), load_status
    
    try:
        print(f"Generating image: {prompt}")
        
        with torch.no_grad():
            image = pipe(
                prompt=prompt,
                num_inference_steps=steps,
                guidance_scale=guidance_scale,
                generator=torch.Generator(device="cpu").manual_seed(42)
            ).images[0]
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"outputs/generated_image_{timestamp}.png"
        image.save(filename)
        
        info_content = f"""Image Generation
Time: {datetime.datetime.now()}
Prompt: {prompt}
Model: {model_id}
Steps: {steps}
Guidance: {guidance_scale}
File: {filename}
"""
        with open("outputs/generation_log.txt", "a") as f:
            f.write(info_content + "\n" + "="*50 + "\n")
        
        success_msg = f"âœ… Image generated!\nSaved as: {filename}"
        print(success_msg)
        return image, success_msg
        
    except Exception as e:
        error_msg = f"âŒ Generation failed: {str(e)}"
        print(error_msg)
        return create_fallback_image(prompt), error_msg

with gr.Blocks(theme=gr.themes.Soft(), title="Text-to-Image Generator") as demo:
    gr.Markdown("# ðŸŽ¨ Text-to-Image AI Generator")
    
    with gr.Row():
        with gr.Column():
            prompt_input = gr.Textbox(
                label="Prompt",
                value="A beautiful sunset over mountains, digital art",
                lines=3,
                placeholder="Describe the image you want to generate..."
            )
            
            model_dropdown = gr.Dropdown(
                choices=[
                    "runwayml/stable-diffusion-v1-5",
                    "stabilityai/stable-diffusion-2-1"
                ],
                value="runwayml/stable-diffusion-v1-5",
                label="Model"
            )
            
            with gr.Row():
                steps_slider = gr.Slider(
                    minimum=5,
                    maximum=50,
                    value=20,
                    step=1,
                    label="Inference Steps"
                )
                
                guidance_slider = gr.Slider(
                    minimum=1.0,
                    maximum=20.0,
                    value=7.5,
                    step=0.5,
                    label="Guidance Scale"
                )
            
            generate_btn = gr.Button("âœ¨ Generate Image", variant="primary", size="lg")
            status_output = gr.Textbox(label="Status", interactive=False)
        
        with gr.Column():
            image_output = gr.Image(
                label="Generated Image", 
                height=512,
                show_download_button=True
            )
    
    gr.Examples(
        examples=[
            ["A beautiful sunset over mountains, digital art"],
            ["A cyberpunk cityscape at night with neon lights"],
            ["A cute cartoon robot in a garden, colorful"],
            ["A majestic dragon flying over a medieval castle"]
        ],
        inputs=prompt_input
    )
    
    generate_btn.click(
        fn=generate_image,
        inputs=[prompt_input, model_dropdown, steps_slider, guidance_slider],
        outputs=[image_output, status_output]
    )

if __name__ == "__main__":
    print("ðŸš€ Starting Text-to-Image Generator...")
    load_model("runwayml/stable-diffusion-v1-5")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        quiet=True
    )
EOF

    - name: Start the image generation web app
      run: |
        echo "Starting Gradio web interface..."
        python app.py &
        echo "APP_PID=$!" >> $GITHUB_ENV
        sleep 15
        echo "âœ… Web app started on port 7860"

    - name: Start Ngrok tunnel
      run: |
        echo "Starting Ngrok tunnel to port 7860..."
        ngrok http 7860 --log=stdout > ngrok.log 2>&1 &
        echo "NGROK_PID=$!" >> $GITHUB_ENV
        sleep 15

    - name: Get Ngrok public URL
      id: get_url
      run: |
        echo "Getting Ngrok public URL..."
        max_attempts=12
        for i in $(seq 1 $max_attempts); do
          if curl -s http://localhost:4040/api/tunnels > /dev/null; then
            NGROK_URL=$(curl -s http://localhost:4040/api/tunnels | jq -r '.tunnels[0].public_url // empty')
            
            if [ -n "$NGROK_URL" ] && [ "$NGROK_URL" != "null" ]; then
              echo "âœ… Ngrok URL: $NGROK_URL"
              echo "ngrok_url=$NGROK_URL" >> $GITHUB_OUTPUT
              echo "NGROK_PUBLIC_URL=$NGROK_URL" >> $GITHUB_ENV
              break
            fi
          fi
          echo "Attempt $i/$max_attempts failed, retrying..."
          sleep 5
        done

        if [ -z "$NGROK_PUBLIC_URL" ]; then
          echo "âŒ Could not get Ngrok URL"
          echo "Ngrok logs:"
          cat ngrok.log
          exit 1
        fi

    - name: Display connection information
      run: |
        echo ""
        echo "âœ¨ ========================================="
        echo "âœ¨   TEXT-TO-IMAGE GENERATOR READY!"
        echo "âœ¨ ========================================="
        echo "âœ¨ Web Interface: $NGROK_PUBLIC_URL"
        echo "âœ¨ Local Port: 7860"
        echo "âœ¨ Default Prompt: ${{ github.event.inputs.prompt }}"
        echo "âœ¨ Model: ${{ github.event.inputs.model }}"
        echo "âœ¨ Steps: ${{ github.event.inputs.steps }}"
        echo "âœ¨ Guidance: ${{ github.event.inputs.guidance }}"
        echo "âœ¨ ========================================="
        echo ""
        echo "ðŸ“ How to use:"
        echo "   1. Open the URL above in your browser"
        echo "   2. Enter your prompt or use examples"
        echo "   3. Adjust settings if needed"
        echo "   4. Click 'Generate Image'"
        echo "   5. Wait 1-2 minutes for generation"
        echo "   6. Download your image"

    - name: Test the web interface
      run: |
        echo "Testing web interface..."
        if curl -f -s "$NGROK_PUBLIC_URL" > /dev/null; then
          echo "âœ… Web interface is accessible"
        else
          echo "âš ï¸  Web interface test failed, but continuing..."
        fi

    - name: Generate initial sample image
      env:
        PROMPT: ${{ github.event.inputs.prompt }}
        MODEL: ${{ github.event.inputs.model }}
        STEPS: ${{ github.event.inputs.steps }}
        GUIDANCE: ${{ github.event.inputs.guidance }}
      run: |
        echo "Generating initial sample image..."
        cat > generate_sample.py << 'EOF'
import os
import torch
from diffusers import StableDiffusionPipeline
from PIL import Image
import datetime

def generate_sample():
    prompt = os.getenv('PROMPT', 'A beautiful landscape')
    model_id = os.getenv('MODEL', 'runwayml/stable-diffusion-v1-5')
    steps = int(os.getenv('STEPS', 20))
    guidance = float(os.getenv('GUIDANCE', 7.5))
    
    print(f"Generating sample: {prompt}")
    
    try:
        pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float32
        )
        pipe = pipe.to("cpu")
        pipe.enable_attention_slicing()
        
        image = pipe(
            prompt=prompt,
            num_inference_steps=steps,
            guidance_scale=guidance
        ).images[0]
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"outputs/sample_{timestamp}.png"
        image.save(filename)
        print(f"âœ… Sample saved: {filename}")
        
    except Exception as e:
        print(f"âŒ Sample generation failed: {e}")
        from PIL import Image, ImageDraw
        img = Image.new('RGB', (512, 512), color='darkblue')
        draw = ImageDraw.Draw(img)
        draw.text((50, 200), f"Sample: {prompt}", fill='white')
        draw.text((50, 230), "Model loading for web interface...", fill='yellow')
        filename = f"outputs/fallback_{timestamp}.png"
        img.save(filename)

if __name__ == "__main__":
    generate_sample()
EOF
        python generate_sample.py

    - name: Keep service running with monitoring
      run: |
        echo "ðŸ• Text-to-Image service active for 30 minutes..."
        echo "ðŸŒ Your Web Interface: $NGROK_PUBLIC_URL"
        echo ""
        echo "ðŸ“ˆ Monitoring service status..."
        
        for i in {1..180}; do
          minutes=$((i/6))
          seconds=$((i%6*10))
          echo "[$(date +%H:%M:%S)] Service active for ${minutes}m ${seconds}s"
          
          if [ $((i % 12)) -eq 0 ]; then
            if curl -s "$NGROK_PUBLIC_URL" > /dev/null; then
              echo "   âœ… Web interface: Accessible"
            else
              echo "   âš ï¸  Web interface: Unreachable"
            fi
            
            image_count=$(find outputs/ -name "*.png" 2>/dev/null | wc -l)
            echo "   ðŸ“· Total images generated: $image_count"
          fi
          
          sleep 10
        done

    - name: Upload generated images
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ai-generated-images
        path: outputs/
        retention-days: 30
        if-no-files-found: warn

    - name: Cleanup
      if: always()
      run: |
        echo "ðŸ§¹ Cleaning up..."
        pkill -f "python app.py" 2>/dev/null || true
        pkill -f ngrok 2>/dev/null || true
        sleep 3
        echo "âœ… Cleanup complete"
        echo "ðŸ“Š Final statistics:"
        find outputs/ -name "*.png" 2>/dev/null | wc -l | xargs echo "Total images:"
